<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="VoiceOver makes the theoretical possible, again!">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>VoiceOver Recognition | Devin's Site</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:700,900" rel="stylesheet">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../../rss.xml">
<link rel="canonical" href="https://devinprater.github.io/posts/voiceover-recognition/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Devin Prater">
<link rel="prev" href="../../posts/switching-tools/" title="Switching Tools" type="text/html">
<link rel="next" href="../../posts/test/" title="test" type="text/html">
<meta property="og:site_name" content="Devin's Site">
<meta property="og:title" content="VoiceOver Recognition">
<meta property="og:url" content="https://devinprater.github.io/posts/voiceover-recognition/">
<meta property="og:description" content="VoiceOver makes the theoretical possible, again!">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2020-10-25T12:28:35-05:00">
<meta property="article:tag" content="apple">
<meta property="article:tag" content="blindness">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Header and menu bar -->
<div class="container">
      <header class="blog-header py-3"><div class="row nbb-header align-items-center">
          <div class="col-md-3 col-xs-2 col-sm-2" style="width: auto;">
            <button class="navbar-toggler navbar-light bg-light nbb-navbar-toggler" type="button" data-toggle="collapse" data-target=".bs-nav-collapsible" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse bs-nav-collapsible bootblog4-search-form-holder">
                
<!-- DuckDuckGo custom search -->
<form method="get" id="search" action="https://duckduckgo.com/" class="navbar-form pull-left">
<input type="hidden" name="sites" value="https://devinprater.github.io/"><input type="hidden" name="k8" value="#444444"><input type="hidden" name="k9" value="#D51920"><input type="hidden" name="kt" value="h"><input type="text" name="q" maxlength="255" placeholder="Searchâ€¦" class="span2" style="margin-top: 4px;"><input type="submit" value="DuckDuckGo Search" style="visibility: hidden;">
</form>
<!-- End of custom search -->

            </div>
        </div>
          <div class="col-md-6 col-xs-10 col-sm-10 bootblog4-brand" style="width: auto;">
            <a class="navbar-brand blog-header-logo text-dark" href="../../">

            <span id="blog-title">Devin's Site</span>
        </a>
          </div>
            <div class="col-md-3 justify-content-end align-items-center bs-nav-collapsible collapse flex-collapse bootblog4-right-nav">
            <nav class="navbar navbar-light bg-white"><ul class="navbar-nav bootblog4-right-nav">
<li class="nav-item">
    <a href="../../posts/voiceover-recognition/index.md" id="sourcelink" class="nav-link">Source</a>
    </li>


                    
            </ul></nav>
</div>
    </div>
</header><nav class="navbar navbar-expand-md navbar-light bg-white static-top"><div class="collapse navbar-collapse bs-nav-collapsible" id="bs-navbar">
            <ul class="navbar-nav nav-fill d-flex w-100">
<li class="nav-item">
<a href="../../archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="../../categories/" class="nav-link">Tags</a>
                </li>
<li class="nav-item">
<a href="../../rss.xml" class="nav-link">RSS feed</a>

                
            </li>
</ul>
</div>
<!-- /.navbar-collapse -->
</nav>
</div>

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="../../posts/voiceover-recognition/" class="u-url">VoiceOver Recognition</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Devin Prater
            </span></p>
            <p class="dateline">
            <a href="../../posts/voiceover-recognition/" rel="bookmark">
            <time class="published dt-published" datetime="2020-10-25T12:28:35-05:00" itemprop="datePublished" title="2020-10-25 12:28">2020-10-25 12:28</time></a>
            </p>
                <p class="commentline">
        
        <a href="../../posts/voiceover-recognition/#utterances-thread">Comments</a>


            
        </p>
<p class="sourceline"><a href="../../posts/voiceover-recognition/index.md" class="sourcelink">Source</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<h3>Introduction</h3>
<p>At the launch of the iPhone 3GS, Apple unveiled VoiceOver on the iPhone. Blind users and accessibility experts had been used to screen readers on computers, and even rudimentary screen readers for smart phones that used a keyboard, trackball, or quadrants of a touch screen for navigation and usage. But here was a screen reader that not only came prepackaged on a modern, relatively inexpensive to the competition, and off-the-shelf device, but it also allowed the user to use the touch screen as it is, a touch device.</p>
<p>This year, VoiceOver added a feature called "VoiceOver recognition." This feature allows VoiceOver to utilize the machine learning coprocessor in newer iPhone models to describe images with near-human quality, make apps more accessible using ML models, and read the text in images.</p>
<p>This article will explore these new features, go into their benefits, compare VoiceOver Recognition to other options, and discuss the history of these features, and what's next.</p>
<h3>VoiceOver Recognition, the features</h3>
<p>VoiceOver Recognition, as discussed before, contains three separate features: Image Recognition, Screen Recognition, and Text recognition. All three work together to bring the best experience. In accessible apps and sites, though, Image and Text recognition do the job fine. All three features must be downloaded and turned on in VoiceOver settings. Image recognition acts upon images automatically, employing Text recognition when text is found in an image.</p>
<p>Screen recognition makes inaccessible apps as good as currently possible with the ML (Machine Learning) model. It is still great, though. It allows me to play Final Fantasy Record Keeper quite easily. It is not perfect, but it is only the beginning!</p>
<h3>Benefits of VoiceOver Recognition</h3>
<p>Imagine, if you are sighted, that you have never seen a picture before, or if you have, that you've never seen a picture you've taken yourself. Imagine that all the pictures you have viewed on social media have been blurry and vague. Sure, you can see some movies, but they are far and few between. And apps? You can only access a few, relative to the number of total apps. And games are laughably simple and forgettable.</p>
<p>That is how digital life is for blind people. Now, however, we have a tool that
helps with that immensely. VoiceOver Recognition gives amazing descriptions for
photos. Not perfect, and sometimes when playing a game, I just get "A photo of a
video game" as a description, but again, this is the first version. And photos
in news articles and on websites, and in apps, are amazingly accurate. If I
didn't know better, I would think someone at Apple is busy describing all the
images I come across. While Screen Recognition can fail spectacularly sometimes,
especially with apps that do not look native to iOS, it has allowed me to get
out of sticky situations in some apps and has allowed me to press the occasional button that VoiceOver can't press due to poor app coding and such.
And I can play a few text-heavy games with it, like Game of Thrones, a tale of
crows.</p>
<p>Even my ability to take pictures is greatly enhanced with image recognition. With this feature, I can open the Camera app, put VoiceOver focus on the "view finder," and it will describe what is in the camera view! When it changes, I must move focus away and back to the View Finder, but that's a small price to pay for a "talking camera" that is actually accurate.</p>
<h3>Comparing VO Recognition to Other Options</h3>
<p>Blind people may then say "Okay, what about Narrator on Windows? It does the same thing, right?" No. First, the photo is sent to a server owned by Microsoft. On iOS, the photo is captioned using the ML Coprocessor. What Microsoft needs and Internet connection and remote server to do, Apple does far better with the chip on your device!</p>
<p>You may then say "Well, how does it give better results?" First, it's automatic. Land on an image, and it works! Second, it is not shy about what it thinks it sees. If it is confident in its description, it will simply describe it. Narrator, and Seeing AI, always say "Image may contain: " before giving a guess. And, with more complex images, Narrator fails, and so does Seeing AI. I have read that this is set to improve, but I've not seen the improvements yet. Only when VoiceOver Recognition isn't confident in what it sees, it says, "Photo contains," and then gives a list of objects that it is surer of. This does not happen nearly as frequently as Narrator/Seeing AI, though.</p>
<p>You may also say "Okay, so how is this better than NVDA's OCR? You can use it to click on items in an app." Yes, and that is great, it really is, and I thank the NVDA developers every time I use VMWare with Linux because there always seems to be something going on with it. But with VoiceOver Recognition, you get an actual natively "accessible," app. You don't have to click on anything, and you know what VoiceOver thinks the item type of something is: a button, text field, ETC., and can interact with the item accordingly. With NVDA, you have a sort of mouse. With VO Recognition, you have an entire app experience.</p>
<h3>The history of these features</h3>
<p>Using AI to bolster the accessibility of user Interfaces is not a new idea. It has been floating around the blind community for a while now. I remember discussing it on an APH (American Printing House for the Blind) mailing list around a decade ago. Back then, however, it was just a toy idea. No one thought it could be done with current, at the time, Android 2.3 era hardware or software. It continued to be brought up by blind people who dreamed bigger than I, but never really went anyway.</p>
<p>Starting with the iPhone X R, Apple began shipping a machine learning Coprocessor within their iPhones. Then n iOS 13, VoiceOver gained the ability to describe images. This was not using the ML chip, however, since older phones could take advantage of it. I thought they may improve this, but I had no idea they would do as great a job as they are doing with iOS 14.</p>
<h4>What's Next?</h4>
<p>As I've said a few times now, this is only version one. I suspect Apple will continue building on their huge success this year, fleshing out Screen recognition, and perhaps having VoiceOver automatically speak what's in the camera view when preparing to take a picture, and perhaps adding even more than I cannot imagine now. I suspect, however, that this is leading to an even larger reveal for accessibility in the next few years, Augmented and Virtual reality. Apple Glasses, after all, would be very useful if they could describe what's around a blind person.</p>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/apple/" rel="tag">apple</a></li>
            <li><a class="tag p-category" href="../../categories/blindness/" rel="tag">blindness</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../../posts/switching-tools/" rel="prev" title="Switching Tools">Previous post</a>
            </li>
            <li class="next">
                <a href="../../posts/test/" rel="next" title="test">Next post</a>
            </li>
        </ul></nav></aside><section class="comments hidden-print"><h2>Comments</h2>
        
        
        <div data-title="VoiceOver Recognition" id="utterances-thread"></div>
        <script src="https://utteranc.es/client.js" repo="devinprater/devinprater.github.io" issue-term="pathname"></script></section></article><!--End of body content--><footer id="footer">
            Contents Â© 2020         <a href="mailto:r.d.t.prater@gmail.com">Devin Prater</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
<a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
<img alt="Creative Commons License BY-NC-SA" style="border-width:0; margin-bottom:12px;" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"></a>
            
            
        </footer>
</div>
</div>


        <script src="../../assets/js/all-nocdn.js"></script><script src="https://polyfill.io/v3/polyfill.js?features=Intl.RelativeTimeFormat.%7Elocale.en"></script><script src="../../assets/js/luxon.min.js"></script><!-- fancy dates --><script>
        luxon.Settings.defaultLocale = "en";
        fancydates(2, {"preset": false, "format": "yyyy-MM-dd HH:mm"});
        </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
